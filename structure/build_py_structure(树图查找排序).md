# 查找
    顺序查找
        无序表的顺序查找，按下标逐个排查，到最后一个仍然没有则查找失败
    无序表和有序表的顺序查找复杂度都是 O(N), 有序表的比对次数可能会比无序表小
        O(n)
    
    二分查找
        分而治之，将若干问题缩小，适合 递归解法
        O(logn)
    ## 约化(Reducibility，有的资料上叫“归约”
        一个问题A可以约化为问题B的含义即是，可以用问题B的解法解决问题A，或者说，问题A可以“变成”问题B。
        《算法导论》上举了这么一个例子。比如说，现在有两个问题：求解一个一元一次方程和求解一个一元二次方程。
        那么我们说，前者可以约化为后者，意即知道如何解一个一元二次方程那么一定能解出一元一次方程
         “问题A可约化为问题B”有一个重要的直观意义：B的时间复杂度高于或者等于A的时间复杂度。也就是说，问题A不比问题B难。
         约化具有传递性。如果问题A可约化为问题B，问题B可约化为问题C，则问题A一定可约化为问题C。这个道理非常简单，就不必阐述了.
         对于程序而言，如果能找到一个变化法则，对任意一个程序A对输入，都能按这个法则变换成程序B的输入，使两程序输出相同，那么我们说问题A可以约化为问题B.
         我们所说的“可约化”是指的可“多项式地”约化(Polynomial-time Reducible)，即变换输入的方法是能在多项式的时间里完成的。约化的过程只有用多项式的时间完成才有意义.
                
    ## 多项式时间和归约问题
    P/NP/NPC/NP-hard问题
    P: 能在多项式时间内解决的问题
    NP: 不能在多项式时间内解决或不确定能不能在多项式时间内解决，但能在多项式时间验证的问题
        NP问题就是指其解的正确性可以在多项式时间内被检查的一类问题。比如说数组求和，得到一个解，这个解对不对呢，显然是可以在多项式时间内验证的。
    NPC: NP完全问题，所有NP问题在多项式时间内都能约化(Reducibility)到它的NP问题，即解决了此NPC问题，所有NP问题也都得到解决。 
        如旅行商问题，如果有10个城市需要到访，找出其中最短路径，那么需要计算 10! 个路径并选择最短的。
        集合覆盖问题也是NP完成问题。 
    NPC问题的定义非常简单。同时满足下面两个条件的问题就是NPC问题。
          首先，它得是一个NP问题；
          然后，所有的NP问题都可以约化到它。证明一个问题是 NPC问题也很简单。
          先证明它至少是一个NP问题，再证明其中一个已知的NPC问题能约化到它（由约化的传递性，则NPC问题定义的第二条也得以满足
    NP hard:NP难问题，所有NP问题在多项式时间内都能约化(Reducibility)到它的问题(不一定是NP问题)。
        NP-Hard问题。NP-Hard问题是这样一种问题，它满足NPC问题定义的第二条但不一定要满足第一条（就是说，NP-Hard问题要比 NPC问题的范围广
    
    信息学的问题: 有P属于NP。现在，所有对NP问题的研究都集中在一个问题上，即究竟是否有P=NP？通常所谓的“NP问题”，其实就一句话：证明或推翻P=NP
    
##    散列  Hashing
        散列表，hash table  哈希表
        散列表(hash table，又称哈希表)是一 种数据集，其中数据项的存储方式尤其有 利于将来快速的查找定位.
        * 实现从数据项到存储槽名称的转换的，称 为散列函数(hash function)
        * 负载因子

            哈希表装填因子定义为：α= 填入表中的元素个数 / 哈希表的长度
            α是哈希表装满程度的标志因子。由于表长是定值，α与“填入表中的元素个数”成正比，所以，α越大，填入表中的元素较多，产生冲突的可能性就越大；α越小，填入表中的元素较少，产生冲突的可能性就越小
            例:一个11个槽位的hash表，将装入6个数据元素，那么负载因子就是 6/11=0.55
            
            散列表中的每一个存储位置，称为槽( slot)，可以用来保存数据项，每个槽有 一个唯一的名称
        
        由数据项的值来确定其存放位置
        
        是一种数据集，其中数据项存储方式尤其有利于将来快速查找定位
        O(1)
        能够使得查找的次数降低到常数级别，我 们对数据项所处的位置就必须有更多的先 验知识
        事先能知道要找的数据项应该出 现在数据集中的什么位置，就可以直接到 那个位置看看数据项是否存在即可。
        * 由数据项的值来确定其存放位置，如何能 做到这一点呢?
        
        例: 一个包含11个槽的散列表，槽的名 称分别为0~10
        
        * 构造方法:
        1。取余法:
        取关键字被不大于哈希表长m的某个树p出后的余数为哈希地址 的方法
                    H(key) = key MOD p (p<=m)  p取为质数或不含小于20质因子的合数
                    序列:[27,17,9,19,16,43,53,8,63]
                         3   1 1  3  0  3  5  0 7
                    H(key) = key MOD 8 + 链地址冲突法
                     16 17 9 27 19 43 53 8  63
                     0  1  2 3  4  5  6  7  8  9  10  11
                    所以如果要查找到 43，原余数位为3号，但是实际需要匹配27，19，43 共3次
         
         
         
        2。折叠法
            折叠法设计散列函数的基本步骤是
            将数据项按照位数分为若干段，再将几段数字相加，最后对散列表大小求余，得到散列值
            *有时候折叠法还会包括一个隔数反转的步 骤,比如(62、76、72、55)隔数反转为(62、67 、72、55),再累加(62+67+72+55=256),对11求余(256%11=3)，所以h'(62767255)=3
             这个步骤确实为折叠法得到散列函数提供 了一种微调手段
            
            例:电话号码62767255,可以两位两位分为4段(62、76、72、55),相加(62+76+72+55=265),散列表包括11个槽，那么就是265%11=1
                所以h(62767255)=1
            
        3, 平方取中法
        平方取中法，首先将数据项做平方运算， 然后取平方数的中间两位，再对散列表的 大小求余
        首先44*44=1936，然后取中间的93，对散列表大小11求余，93%11=5   
        
        4， 非数项
        我们也可以对非数字的数据项进行散列， 把字符串中的每个字符看作ASCII码即可
        如cat，ord('c')==99, ord('a')==96, ord('t')==116
        再将这些整数累加，对散列表大小求余， 99+96+116 = 312， 312 % 11  = 4
        
            def hash_mat(astring,tablesize):
                sum = 0
                for p in range(len(astring)):
                    sum += ord(astring[p])
                return sum%tablesize
            缺点: 散列函数对所有的变位词都 返回相同的散列值
                解决，为了防止这一点，可以将字符串所在的位置作为 权重因子，乘以ord值
        散列函数设计原则: 散列函数 不能成为存储过程和查找过程的计算负担 
        如果散列函数设计太过复杂，去花费大量 的计算资源计算槽号 可能还不如简单地进行顺序查找或者二分查找       
            
        * 完美散列函数
        如果一个散列函数能把 每个数据项映射到不同的槽中，那么这个散列函数就可以称为“完美散列函数” 对于固定的一组数据，总是能想办法设计出完美 散列函数
        如果数据项经常性的变动，很难有一个系统性的方法来设计对应的完美散列函数
        好的散列算法:冲突最少(近似完美)、计算难度低(额外开销 小)、充分分散数据项(节约空间)
        
        压缩性:任意长度的数据，得到的“指纹”长度是固定的;
        易计算性:从原数据计算“指纹”很容易;(从指纹计算原数据是不可能的);
        抗修改性:对原数据的微小变动，都会引起“指纹”的大改变;
        抗冲突性:已知原数据和“指纹”，要找到相同指纹的数据(伪造)是非常困难的
        
        * 散列冲突解决
        完美散列函数的一种方法是扩大散列 表的容量，大到所有可能出现的数据项都 能够占据不同的槽
        类似于无限旅馆问题: 奇偶,同构 2**n 奇数来插入不同位置
            如果两个数据项被散列映射到同一个槽， 需要一个系统化的方法在散列表中保存第 二个数据项，这个过程称为“解决冲突”
            冲突解决方法1:为冲突的数据项 再找一个开放的空槽来保存
                最简单的就是从冲突的槽开始往后扫描，直到碰到一个空槽如果到散列表尾部还未找到，则从首部接着扫描
                寻找空槽的技术称为“开放定址 open addressing"
                向后逐个槽寻找的方法则是开放定址技术 中的“线性探测linear probing”
                h(44)=0，但发现0#槽已被77占据，向后找到第 一个空槽1#，保存
                h(55)=0，同样0#槽已经被占据，向后找到第一 个空槽2#，保存
                h(20)== 9，发现9#槽已经被31占据了，向后， 再从头开始找到3#槽保存
            
            1，如果采用线性探测方法来解决散列冲突， 则散列表的查找也遵循同样的规则。
            2，如果在散列位置没有找到查找项的话，就必须向 后做顺序查找直到找到查找项，或者碰到空槽(查找失败)
        线性探测的聚集问题
            线 性 探 测 法 的 一 个 缺 点 是 有 聚 集 ( clustering)的趋势
            即如果同一个槽冲突的数据项较多的话， 这些数据项就会在槽附近聚集起来
            从而连锁式影响其它数据项的插入
            
            将线性探测扩展 ，从逐个探测改为跳跃式探测
            
            冲突解决方法2:再散列rehashing
            newhashvalue = rehash(oldhashvalue)
            对于线性探测来说，rehash(pos)= (pos+ 1)% sizeoftable
            “+3”的跳跃式探测则是:rehash(pos)= (pos+ 3)% sizeoftable
            跳跃式探测的再散列通式是:rehash(pos)= (pos+skip)% sizeoftable
            跳跃式探测中，需要注意的是skip的取值，不能被散列表大小整除，否则会产生周期，造成很多空槽永远无法探测到
            
            一个技巧是，把散列表的大小设为素数，如例子 的11
            还 可 以 将 线 性 探 测 变 为 “ 二 次 探 测 quadratic probing
            不再固定skip的值，而是逐步增加skip值 ，如1、3、5、7、9
            这样槽号就会是原散列值以平方数增加: h, h+1, h+4, h+9, h+16...
            
            冲突解决方法3:冲突解决方案:数据项链Chaining
            除了寻找空槽的开放定址技术之外，另一 种解决散列冲突的方案是将容纳单个数据 项的槽扩展为容纳数据项集合(或者对数据项链表的引用
            这样，散列表中的每个槽就可以容纳多个 数据项，如果有散列冲突发生，只需要简 单地将数据项添加到数据项集合中
            当然，随着散列冲突的增加，对 数据项的查找时间也会相应增加
            
        # 抽象数据类型“映射” ADT Map
        其中关键码key可用于查询关联的数据值data
        键值关联的方法称为“映射Map”
        ADT Map的结构是键-值关联的无序集合
        关键码具有唯一性,通过关键码可以唯一确定一个数据值
        Map():创建一个空映射，返回空映射对象;
        put(key, val):将key-val关联对加入映射中 ，如果key已存在，将val替换旧关联值;
        get(key):给定key，返回关联的数据值，如不 存在，则返回None;
        del:通过del map[key]的语句形式删除key- val关联;
        len():返回映射中key-val关联的数目;
        in:通过key in map的语句形式，返回key是否 存在于关联中，布尔值
        
        使用字典的优势在于，给定关键码key， 能够很快得到关联的数据值data
        为了达到快速查找的目标，需要一个支持 高效查找的ADT实现
        可以采用列表数据结构加顺序查找或者二分查找,当然，更为合适的是使用前述的散列表来实现， 这样查找可以达到最快O(1)的性能
        class  HashTable:
            def __init__(self_):
                self.size=11
                self.slots=[None]*self.size
                self.data=[None]*self.size
               
        * 应用  任意长度的数据生成长度固定的“指纹”，还要求具备唯一性
        完美散列函数能够对任何不同的数据 生成不同的散列值，如果把散列值当作数 据的“指纹”或者“摘要”，这种特性被 广泛应用在数据的一致性校验上
            1，由任意长度的数据生成长度固定的“指纹”，还要求具备唯一性，这在数学上是无法做到的，但设计巧妙的“准完美”散列函数却能在实用范围内做到这一点。
            2，数据文件一致性判断
            3，为每个文件计算其散列值，仅对比其散列值即可得知是否文件内容相同
            4，用于网络文件下载完整性校验;
            5，用于文件分享系统:网盘中相同的文件( 尤其是电影)可以无需存储多次。
            6，数据一致性校验
                加密形式保存密码
                仅保存密码的散列值，用户输入密码后，计算散列值并比对;
                无需保存密码的明文即可判断用户是否输 入了正确的密码
                防文件篡改:原理同数据文件一致性判断
                彩票投注应用
        
        
#### 散列应用- 区块链
        区块链由一个个区块(block)组成，区 块分为头(head)和体(body)
        特点:
        区块头记录了一些元数据和链接到前一个 区块的信息
            生成时间、前一个区块(head+body)的散列值
        区块体记录来实际数据
        
        去中心化(分布式)，共识算法，安全
        通过网络连接的节点
        区块链是一种分布式数据库
        每个节点都保存着整个数据库所有数据
        任何地点存入的数据都会完成同步
        由于散列值具有抗修改性，任何对某个区 块数据的改动必然引起散列值的变化
        
        * 工作量证明:Proof of Work(POW)
        目前最大规模区块链Bitcoin采用的速度是平均 每10分钟生成一个区块
        大家不惜付出海量的计算，去抢着算出一 个区块的有效散列值
        最先算出的那位“矿工”才有资格把区块 挂到区块链中
        
        区块很难算出
            因为很难算出，所以控制了新区块生成的 速度，便于在整个分布式网络中进行同步
            每个区块设置了一个难度系数Difficulty ，用常数targetmax除以它，得到一个 target，难度系数越高，target越小
            找到一个数值Nonce，把 它跟整个区块数据一起计算散列，这个散 列值必须小于target，才是有效的散列值
            由于散列值无法回推原值，这个Nonce的 寻找只能靠暴力穷举，计算工作量+运气 是唯一的方法
            硬件摩尔定律，挖矿计算力升级:CPU(20MHash/s)→GPU( 400MHash/s)→FPGA(25GHash/s)→ASIC( 3.5THash/s)→大规模集群挖矿( 3.5THash/s*X)
            
        在加密货币Bitcoin中，区块内包含的数 据是“交易记录”，也就是“账本”，这 对于货币体系至关重要
        Bitcoin规定，每个区块中包含了一定数 量的比特币作为“记账奖励”，这样就鼓 励了更多人加入到抢先记账的行列
        
        举例:完美散列函数是MD5和 SHA系列函数
        MD5:Message Digest)将任何长度的数据变换为固定长为128位(16字节)的“摘要”
            128位二进制已经是一个极为巨大的数字空间: 据说是地球沙粒的数量
        SHA(Secure Hash Algorithm)是另 一组散列函数
            SHA-0/SHA-1输出散列值160位(20字节)
            SHA-256/SHA-224分别输出256位、224位，
            SHA-512/SHA-384分别输出512位和384位
            160位二进制相当于10的48次方，地球上 水分子数量估计是47次方
            256位二进制相当于10的77方，已知宇宙 所有基本粒子大约是72~87次方
        * python 库 hashlib
            包括了md5 / sha1 / sha224 / sha256 / sha384 / sha512等6种散列函数
            hashlib.md5("hello").hexdigest()
            hashlib.sha1('hello').hexdigest()
            
            除了对单个字符串进行散列计算之外，还可以用update方法来对任意长的数据分部分来计算
            这样不管多大的数据都不会有内存不足的 问题
    
# 排序
    代码 structure/base_code/searchPolicy
    冒泡排序 Bubble sort
        每一趟把最大的放到最后
        冒泡排序性能优化，不能降低计算复杂度
        
        最差O(n**2)
    选择排序
        冒泡排序的优化
        O(N)
    插入排序
        O(N**2)
        [17,26,54,77,93,31,44,55,20]
        取出待排序数 31
        [17,26,54,77,None,93,44,55,20]  # 93 大于31 所以向右移动一位
        [17,26,54,None,77,93,44,55,20]  # 77也大于31，所以77向右移动一位
        [17,26,None,54,77,93,44,55,20]  # 54也大于31，所以54向右移动一位
        [17,26,31,54,77,93,44,55,20]    # 26小于 31，所以插入31在26右边，54的左边
        
        比对次数最多 O(N)
        列表越接近有序，比对次数越少
    谢尔排序 Shell sort
        插入排序的优化，
        先对子列表排序
        子列表的间隔一般从n/2开始，每趟倍增: n/4,n/8,...直到1
    归并排序 
    
        子列表排序，然后合并子列表
        分裂 和 归并
        时间复杂度
        分裂:借鉴二分查找的复杂度 O(logn) 
        归并: 对于分裂的每个部分，其所有数据项都会被比较和放置一次，所以是线性复杂度。时间复杂度O(N)
        每次分裂的部分都进行一次O(n)的数
        根据归并，总的时间复杂度是 O(nlogn)   
        如果有巨大的数据，归并的存储空间需要考虑
    快速排序 Quick Sort
        递归算法实现，分裂和移动
        随机选择一个数作为"中位数"
        分裂列表为两部分，左标向右移动，右标向左移动
        复杂度 O(nlogn),没有额外的空间复杂度
            极端情况加上递归调用 ,最糟糕时如果中值选择不合适，可能比冒泡还差 O(n**2)
        中值选取方法(头，尾，中部选择3个点，三点取样)，采样方法
        
        
# 树
    数的概念
        略
    术语
        BST搜索树
        树的左子节点都小于根节点，而右子节点都大于根
        AVL搜索树
        平衡二叉搜索树
        
        最小堆 最小的元素在头部
        最大堆 最大的元素在头部
    
    树的嵌套列表实现
        第1个元素为根节点的值;
        第2个元素是左子树(所以也是一个列表); 第3个元素是右子树(所以也是一个列表)。
        [root, left, right]
        根是myTree[0]，左子树myTree[1]，右子树 myTree[2]
         
        嵌套列表法的优点 
            子树的结构与树相同，是一种递归数据结构
            很容易扩展到多叉树，仅需要增加列表元素即可
            
        嵌套实现的函数
            BinaryTree创建仅有根节点的二叉树 insertLeft/insertRight将新节点插入树中作
            为其直接的左/右子节点 get/setRootVal则取得或返回根节点 getLeft/RightChild返回左/右子树
            
    树的链表实现
        * 建立表达式解析式， 代码实践
        
        
    使用节点(node)和引用实现树
        我们第二种实现树的方式使用节点和引用。在这种情况下，我们将定义具有根值，以及左子树 和右子树属性的类。
        由于这种实现方式与面向对象的编程方式联系更紧密，我们将继续使用这种实 现方式完成本章的其余部分
    树的应用
        0，表达式求值，规则
            如果当前单词是"(":为当前节点添加一个新节 点作为其左子节点，当前节点下降为这个新节点
            如果当前单词是操作符"+,-,/,*":将当前节点 的值设为此符号，为当前节点添加一个新节点作 为其右子节点，当前节点下降为这个新节点
            如果当前单词是操作数:将当前节点的值设为此数，当前节点上升到父节点
            如果当前单词是")":则当前节点上升到父节点
            
        1，自然界动物分类
            界
                门
                    纲
                        属
                            种
        2，操作系统的文件系统
        linux
        /
            opt
            etc
            home
                pwd
                admin
        
        3，html文件格式
        html
            head
                meta
                title
            body
                ul
                    li
                    li
                h1
                h2
    * 树的遍历
        ** 代码实践
        后序遍历对表达式求值
    
    优先队列和二叉堆
        优先队列对二叉堆实现，让其时间复杂度保持在 logN，只有二叉树可以实现对数的时间复杂度。
        概念:
        * 完全二叉树(顺序二叉树)
            完全二叉树的叶节点 在树的最底层或-2层
                而且叶节点都尽量靠左方。
        * 堆次序Heap Order
            任何一个节点x，其父节点p中的key均小于x中的key
            根节点是最小的
            这样，符合“堆”性质的二叉树，其中任何一条 路径，均是一个已排序数列，根节点的key最小
        * 插入 在二叉堆操作时，如果把新key插入到堆末尾，可能破坏堆的次序，所以需要有新key的上浮操作 insert
        
        * 删除 delMin()方法。最后的叶节点替换被删除节点后，有下沉操作
            下沉路径选择，如果比子节点大，那么选择较小的子节点下沉
        
    二叉堆的python实现
        buildHeap(lst)方法。从无序表生产堆，下沉法，能够将总代价控制在O(n)
        
        堆排序，复杂度O(nlogn)
    
        
## 二叉查找树(BST)和二叉平衡树(AVL)  
    * 二叉查找树  
        比父节点小的key都出现在左子树，比父节点大的key都出现在右子树
        
    Map的实现方案中，可以采用不同的数据结构和搜索算法来保存和查找
    Key，前面已经实现了两个方案
    有序表数据结构+二分搜索算法 散列表数据结构+散列及冲突解决算法
    二叉查找树，通过二叉查找树保存key， 实现key的快速搜索
    其主要操作包括以下部分
    
    Map():创建一个空映射
    put(key, val):将key-val关联对加入映射中， 如果key已经存在，则将val替换旧关联值;
    get(key):给定key，返回关联的数据值，如不 存在，则返回None;
    del:通过del map[key]的语句形式删除key- val关联;
        节点删除分几种情况，1，删除节点没有子节点；2，删除节点有一个子节点；3，被删除节点有两个子节点
            第三种情况下，如果有两个子节点，将该二叉查找子树 右侧的 最小 的子节点，作为根节点替换 当前被删的子节点即可。
            
    len():返回映射中key-val关联的数目;
    in:通过key in map的语句形式，返回key是否 存在于关联中，布尔值
    例:
        键值1，2，3，4，5，6，7的 七个元素以某种顺序插入某二叉搜索树后，发现树的根为2，这个树的高度可能是 3 或 4 或5
        
    * 平衡二叉树 AVL
        用于实现 ADT Mao，字典等数据结构的底层实现。
        名称由来，是发明者的名字缩写，G.M. Adelson-Velskii and E.M. Landis
        利用AVL树实现ADT map，与二叉查找树BST基本相同，不同之处在于二叉树的生成和维护过程。
        AVL实现过程中，需要对每个节点跟踪 "平衡因子 balance factor" 参数
        
        平衡因子是根据节点对左右子树高度来定义的，具体来讲，就是 左右子树的高度差
            banlanceFactor = height(LeftSubTree) - height(rightSubTree)
        如果平衡因子大于0，称为 '左重left-heavy'，小于零 称为 '右重right-heavy'，平衡因子等于零 称为 '平衡'
    
        * 如果一个二叉查找树每个节点的平衡因子都在-1，0，1之间，则称这个二叉查找树 为 平衡树。
        
        平衡二叉树的最多搜索次数h和规模N的关系， 时间复杂度 O(logN) 
        如何重新平衡?(有节点的平衡因子超过(-1,0,1)的范围)
        
        如果在再平衡的时候，如下图'右重'子树，单纯的左旋无法实现再平衡
        左旋后变成左重，左重再右旋，还是回到 右重
        原右重树T                T1                      又变回右重树T，无法平衡
        A(-2)    ---左旋--->       C2  ----右旋-->       A(-2)
           C(1)                 A1                           C(1)
        B(0)                      B0                     B(0)
        
        此时需要查看原 T，发现子树右子节点有 左重，即 A的右子节点C 有 子节点 B  先对右子节点 右旋，再进行 原计划的左旋，（同样右旋的时候也要检查 左子节点是否右重）
        A(-2)      --子节点C右旋-->     A(-2)            --对树左旋-->      B(0)
            C(1)                         B(-1)                        A(0)   C(0)
        B(0)                                 C(0)
# 图

